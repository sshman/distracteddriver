{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuning - googlenet for distracted driver dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "caffe_root = '../' \n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, caffe_root + 'python')\n",
    "import caffe\n",
    "\n",
    "caffe.set_device(0)\n",
    "caffe.set_mode_gpu()\n",
    "\n",
    "import numpy as np\n",
    "from pylab import *\n",
    "%matplotlib inline\n",
    "import tempfile\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Helper function for deprocessing preprocessed images, e.g., for display.\n",
    "def deprocess_net_image(image):\n",
    "    image = image.copy()              # don't modify destructively\n",
    "    image = image[::-1]               # BGR -> RGB\n",
    "    image = image.transpose(1, 2, 0)  # CHW -> HWC\n",
    "    image += [123, 117, 104]          # (approximately) undo mean subtraction\n",
    "\n",
    "    # clamp values in [0, 255]\n",
    "    image[image < 0], image[image > 255] = 0, 255\n",
    "\n",
    "    # round and cast from float32 to uint8\n",
    "    image = np.round(image)\n",
    "    image = np.require(image, dtype=np.uint8)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the num of labels and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n"
     ]
    }
   ],
   "source": [
    "NUM_DD_LABELS = 10\n",
    "dd_labels = list(range(0,NUM_DD_LABELS))\n",
    "print dd_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from caffe.proto import caffe_pb2\n",
    "\n",
    "def solver(train_net_path, test_net_path=None, base_lr=0.0001, snapshot_prefix = 'ddxx'):\n",
    "    \n",
    "    s = caffe_pb2.SolverParameter()\n",
    "\n",
    "    # Specify locations of the train and (maybe) test networks.\n",
    "    s.train_net = train_net_path\n",
    "    if test_net_path is not None:\n",
    "        s.test_net.append(test_net_path)\n",
    "        s.test_interval = 1000  # Test after every 1000 training iterations.\n",
    "        s.test_iter.append(15) # Test on 100 batches each time we test.\n",
    "        \n",
    "    # The number of iterations over which to average the gradient.\n",
    "    # Effectively boosts the training batch size by the given factor, without\n",
    "    # affecting memory utilization.\n",
    "    s.iter_size = 1\n",
    "    \n",
    "    s.max_iter = 100000     # # of times to update the net (training iterations)\n",
    "    \n",
    "    # Solve using the stochastic gradient descent (SGD) algorithm.\n",
    "    # Other choices include 'Adam' and 'RMSProp'.\n",
    "    s.type = 'Adam'\n",
    "\n",
    "    # Set the initial learning rate for SGD.\n",
    "    s.base_lr = base_lr\n",
    "\n",
    "    # Set `lr_policy` to define how the learning rate changes during training.\n",
    "    # Here, we 'step' the learning rate by multiplying it by a factor `gamma`\n",
    "    # every `stepsize` iterations.\n",
    "    s.lr_policy = 'step'\n",
    "    s.gamma = 0.1\n",
    "    s.stepsize = 20000\n",
    "\n",
    "    # Set other SGD hyperparameters. Setting a non-zero `momentum` takes a\n",
    "    # weighted average of the current gradient and previous gradients to make\n",
    "    # learning more stable. L2 weight decay regularizes learning, to help prevent\n",
    "    # the model from overfitting.\n",
    "#    s.momentum = 0.9\n",
    "#    s.weight_decay = 5e-4\n",
    "\n",
    "    # Display the current training loss and accuracy every 1000 iterations.\n",
    "    s.display = 1000\n",
    "\n",
    "    # Snapshots are files used to store networks we've trained.  Here, we'll\n",
    "    # snapshot every 10K iterations -- ten times during training.\n",
    "    s.snapshot = 100\n",
    "    s.snapshot_prefix = caffe_root + 'models/dd/' + snapshot_prefix\n",
    "    \n",
    "    # Train on the GPU.  Using the CPU to train large networks is very slow.\n",
    "    s.solver_mode = caffe_pb2.SolverParameter.GPU\n",
    "    \n",
    "    # Write the solver to a temporary file and return its filename.\n",
    "    with tempfile.NamedTemporaryFile(delete=False) as f:\n",
    "        f.write(str(s))\n",
    "        return f.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_net_path = '/home/ubuntu/caffe2/caffe/models/googlenet_10class_finetune/googlenet10class_tuneallfc.prototxt'\n",
    "weights = '/home/ubuntu/caffe2/caffe/models/dd/google_fine_3_iter_900.caffemodel'\n",
    "#weights = '/home/ubuntu/caffe2/caffe/models/googlenet_10class_finetune/bvlc_googlenet.caffemodel'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "solver_path = solver(train_net_path, base_lr=0.0001, snapshot_prefix='google_fine_4')\n",
    "solver = caffe.get_solver(solver_path)\n",
    "solver.net.copy_from(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 train loss= 1.58110380173  time= 0.326205968857\n",
      "50 train loss= 1.57639837265  time= 14.8060650826\n",
      "100 train loss= 1.3762332201  time= 29.6404249668\n",
      "150 train loss= 0.919660866261  time= 44.1239509583\n",
      "200 train loss= 1.18341779709  time= 58.9143519402\n",
      "250 train loss= 0.909773826599  time= 73.3944039345\n",
      "300 train loss= 0.913184523582  time= 88.1747879982\n",
      "350 train loss= 0.899425506592  time= 102.654928923\n",
      "400 train loss= 1.05257618427  time= 117.445826054\n",
      "450 train loss= 0.729639530182  time= 131.932982922\n",
      "500 train loss= 0.925218999386  time= 146.730884075\n",
      "550 train loss= 0.492480874062  time= 161.210880995\n",
      "600 train loss= 0.537905216217  time= 176.000396967\n",
      "650 train loss= 0.528548002243  time= 190.482832909\n",
      "700 train loss= 0.53393638134  time= 205.273307085\n",
      "750 train loss= 0.56178945303  time= 219.753696918\n",
      "800 train loss= 0.399997919798  time= 234.547713995\n",
      "850 train loss= 0.38559371233  time= 249.033856869\n",
      "900 train loss= 0.384254157543  time= 263.859920979\n",
      "950 train loss= 0.580393612385  time= 278.341618061\n",
      "999 train loss= 0.439738214016  time= 292.849317074\n"
     ]
    }
   ],
   "source": [
    "niter = 1000\n",
    "disp_interval = 50\n",
    "\n",
    "blobs = ('loss', 'acc')\n",
    "loss = np.zeros(niter)\n",
    "acc = np.zeros(niter)\n",
    "\n",
    "start_time = time.time()\n",
    "for it in range(niter):\n",
    "    solver.step(1)  # run a single SGD step in Caffe\n",
    "    loss[it] = solver.net.blobs['loss1/loss1'].data.copy()\n",
    "    #acc[it] = solver.net.blobs['acc'].data.copy()\n",
    "        \n",
    "    if it % disp_interval == 0 or it + 1 == niter:\n",
    "        #test_loss = 0\n",
    "        #test_acc = 0\n",
    "        #for i in range(0,20):\n",
    "        #    solver.test_nets[0].forward()\n",
    "        #    test_loss = test_loss + solver.test_nets[0].blobs['loss'].data\n",
    "        #    test_acc = test_acc + solver.test_nets[0].blobs['acc'].data\n",
    "        print it, 'train loss=', loss[it] , ' time=', time.time()- start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.221517562866211"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(test_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get output ( deploy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "source = '/home/ubuntu/distracteddriver/data/imgs/output1.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outputnet_path = '/home/ubuntu/caffe2/caffe/models/googlenet_10class_finetune/googlenet10class_deploy.prototxt'\n",
    "weights = '/home/ubuntu/caffe2/caffe/models/dd/google_fine_4_iter_900.caffemodel'\n",
    "outputnet = caffe.Net(outputnet_path,weights, caffe.TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.000503063201904\n",
      "100 27.6660430431\n",
      "200 55.3169541359\n",
      "300 82.9712870121\n",
      "400 110.631191969\n",
      "500 138.291491985\n",
      "600 165.959401131\n",
      "700 193.634925127\n",
      "800 221.320247173\n",
      "900 249.015668154\n",
      "1000 276.724761009\n",
      "1100 304.436163187\n",
      "1200 332.152372122\n",
      "1300 359.863602161\n",
      "1400 387.591262102\n",
      "1500 415.331500053\n",
      "1600 443.085996151\n",
      "1700 470.837129116\n",
      "1800 498.597136974\n",
      "1900 526.365695\n",
      "2000 554.136285067\n",
      "2100 581.917642117\n",
      "2200 609.709833145\n",
      "2300 637.513375044\n",
      "2400 665.314886093\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "max_iter = 79726/32 + 1\n",
    "start_time = time.time()\n",
    "output = np.zeros((1,10))\n",
    "for i in range(0,max_iter):\n",
    "    if (i%100 == 0):\n",
    "        print i , time.time() - start_time        \n",
    "    output = np.append(output,outputnet.forward()['prob'], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outfile = '/home/ubuntu/distracteddriver/outfile_google_fine_allfc.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savetxt(outfile, output, delimiter = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "x = np.arange(0,train_loss.shape[0])\n",
    "plt.plot(x,train_loss)\n",
    "plt.plot(x, train_acc)"
   ]
  }
 ],
 "metadata": {
  "description": "Fine-tune the ImageNet-trained CaffeNet on new data.",
  "example_name": "Fine-tuning for Style Recognition",
  "include_in_docs": true,
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "priority": 3
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
